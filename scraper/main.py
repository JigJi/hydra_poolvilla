import asyncio
import re
import random
import json
import os
import urllib.parse
from datetime import datetime, timedelta
from playwright.async_api import async_playwright
from sqlalchemy.dialects.postgresql import insert
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

from database import DATABASE_URL
from models import Villa

engine = create_async_engine(
    DATABASE_URL, 
    echo=False,
    connect_args={
        "statement_cache_size": 0,         # ‡∏õ‡∏¥‡∏î cache ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pgbouncer
        "prepared_statement_cache_size": 0  # ‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á
    }
)

AsyncSessionLocal = sessionmaker(
    bind=engine, 
    class_=AsyncSession, 
    expire_on_commit=False
)

# --- üéØ CONFIGURATION ---
TARGET_LOCATIONS = [
    {"name": "‡∏´‡∏≤‡∏î‡∏õ‡πà‡∏≤‡∏ï‡∏≠‡∏á", "province": "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï"},
    # {"name": "‡∏ä‡∏∞‡∏≠‡∏≥", "province": "‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ"},
    # {"name": "‡∏´‡∏±‡∏ß‡∏´‡∏¥‡∏ô", "province": "‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå"},
#     {"name": "‡∏û‡∏±‡∏ó‡∏¢‡∏≤‡∏Å‡∏•‡∏≤‡∏á", "province": "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ"},
#     {"name": "‡∏´‡∏≤‡∏î‡∏à‡∏≠‡∏°‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô", "province": "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ"},
#     {"name": "‡∏´‡∏≤‡∏î‡∏ö‡∏≤‡∏á‡πÅ‡∏™‡∏ô", "province": "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ"},
#     {"name": "‡∏ñ‡∏•‡∏≤‡∏á", "province": "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï"},
#     {"name": "‡∏õ‡∏£‡∏≤‡∏ì‡∏ö‡∏∏‡∏£‡∏µ", "province": "‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå"},
]

BASE_URL = "https://www.booking.com/searchresults.th.html"
IMG_BASE_URL = "https://cf.bstatic.com"

PROCESSED_IDS = set()

# --- üíæ DATABASE FUNCTION ---
async def save_snapshot(data):
    async with AsyncSessionLocal() as session:
        try:
            async with session.begin():
                stmt = insert(Villa).values(**data)
                stmt = stmt.on_conflict_do_update(
                    index_elements=[Villa.externalId], # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ï‡∏±‡∏ß‡∏´‡∏•‡∏±‡∏Å
                    set_={
                        "priceDaily": stmt.excluded.priceDaily,
                        "rating": stmt.excluded.rating,
                        "reviewCount": stmt.excluded.reviewCount,
                        "updatedAt": datetime.now(),
                        "isActive": True
                    }
                )
                await session.execute(stmt)
            await session.commit()
            return True
        except Exception as e:
            await session.rollback()
            # --- ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏ß‡πà‡∏≤ slug ‡∏ã‡πâ‡∏≥ ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤ "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡πÉ‡∏ô‡πÅ‡∏á‡πà‡∏Ç‡∏≠‡∏á‡∏ö‡∏≠‡∏ó)" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ ---
            if "UniqueViolationError" in str(e) or "duplicate key" in str(e):
                # print(f"      ‚ÑπÔ∏è  Skipped duplicate slug: {data.get('slug')}")
                return True # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ True ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏ó‡πÑ‡∏õ‡∏ó‡∏≥‡∏ï‡∏±‡∏ß‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
            
            print(f"      ‚ùå DB Error: {e}")
            return False

# --- üõ°Ô∏è POPUP KILLER ---
async def handle_genius_popup(page):
    try:
        popup_selector = 'button[aria-label="‡∏õ‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö"]'
        if await page.is_visible(popup_selector):
            await page.click(popup_selector)
            await page.wait_for_timeout(500)
    except: pass

# --- üïµÔ∏è‚Äç‚ôÇÔ∏è ENGINE 1: JSON LISTENER ---
async def process_json_data(json_data, location_context):
    try:
        results = json_data.get("data", {}).get("searchQueries", {}).get("search", {}).get("results", [])
        if not results: results = json_data.get("results", [])
        if not results: return 0
        
        count = 0
        for item in results:
            basic_info = item.get("basicPropertyData", {})
            if not basic_info: continue
            
            external_id = str(basic_info.get("id"))
            if external_id in PROCESSED_IDS: continue

            slug = basic_info.get("pageName", f"villa-{external_id}")
            title = item.get("displayName", {}).get("text", "Unknown")
            
            loc_data = basic_info.get("location", {})
            real_district = loc_data.get("city") or location_context["name"]
            real_address = loc_data.get("address", "")
            
            main_photo = basic_info.get("photos", {}).get("main", {}).get("highResUrl", {}).get("relativeUrl")
            cover_image = f"{IMG_BASE_URL}{main_photo}" if main_photo else ""
            
            review_score = basic_info.get("reviewScore", {}).get("score", 0)
            review_count = basic_info.get("reviewScore", {}).get("reviewCount", 0)
            
            price = 0
            try:
                blocks = item.get("blocks", [])
                if blocks:
                    final_price = blocks[0].get("finalPrice", {}).get("amount", 0)
                    price = int(final_price)
            except: pass

            villa_data = {
                "externalId": external_id,
                "slug": slug,
                "title": title,
                "province": location_context["province"],
                "district": real_district,
                "address": real_address,
                "priceDaily": price,
                "rating": float(review_score) if review_score else 0,
                "reviewCount": int(review_count) if review_count else 0,
                "coverImage": cover_image,
                "sourceUrl": f"https://www.booking.com/hotel/th/{slug}.html",
                "maxGuests": 2,
                "bedrooms": 1,
                "bathrooms": 1,
                "isActive": True,
                "updatedAt": datetime.now()
            }
            
            if await save_snapshot(villa_data):
                PROCESSED_IDS.add(external_id)
                count += 1
        
        if count > 0:
            print(f"      ‚ö° (JSON) Captured {count} items.")
        return count

    except Exception:
        return 0

# --- üïµÔ∏è‚Äç‚ôÇÔ∏è ENGINE 2: HTML SCRAPER ---
async def scan_current_page_html(page, location_context):
    try:
        await page.wait_for_selector('[data-testid="property-card"]', timeout=3000)
    except: pass

    cards = await page.query_selector_all('[data-testid="property-card"]')
    if not cards: return 0
    
    new_items = 0
    for card in cards:
        try:
            link_el = await card.query_selector('a[data-testid="title-link"]')
            if not link_el: link_el = await card.query_selector('a')
            if not link_el: continue
            
            href = await link_el.get_attribute('href')
            if not href: continue
            clean_url = href.split('?')[0]
            if ".html" not in clean_url and "booking.com" not in clean_url: continue

            slug = clean_url.split('/')[-1].replace('.th.html', '').replace('.html', '')
            external_id = slug
            
            if external_id in PROCESSED_IDS: continue

            title_el = await card.query_selector('[data-testid="title"]')
            title = await title_el.inner_text() if title_el else "Unknown"
            
            price = 0
            price_el = await card.query_selector('[data-testid="price-and-discounted-price"]')
            if price_el:
                raw_price = await price_el.inner_text()
                digits = re.findall(r'\d+', raw_price.replace(',', ''))
                if digits: price = int(''.join(digits))

            img_el = await card.query_selector('[data-testid="image"]')
            cover_image = await img_el.get_attribute('src') if img_el else ""
            
            rating_el = await card.query_selector('[data-testid="review-score-link"] div')
            rating_text = await rating_el.inner_text() if rating_el else "0"
            try: rating = float(rating_text)
            except: rating = 0.0

            villa_data = {
                "externalId": external_id,
                "slug": slug,
                "title": title,
                "province": location_context["province"],
                "district": location_context["name"],
                "priceDaily": price,
                "rating": rating,
                "reviewCount": 0,
                "coverImage": cover_image,
                "sourceUrl": f"https://www.booking.com{clean_url}" if not clean_url.startswith('http') else clean_url,
                "maxGuests": 2,
                "bedrooms": 1,
                "bathrooms": 1,
                "isActive": True,
                "updatedAt": datetime.now()
            }
            
            if await save_snapshot(villa_data):
                PROCESSED_IDS.add(external_id)
                new_items += 1
            
        except Exception:
            continue
    
    if new_items > 0:
        print(f"      üî® (HTML) Swept {new_items} unique items.")
    return new_items

# --- üå™Ô∏è FORCE SCROLL HELPER ---
async def force_scroll_to_bottom(page):
    # Scroll ‡πÅ‡∏ö‡∏ö JS
    await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
    await page.wait_for_timeout(2000)
    
    # Scroll ‡πÅ‡∏ö‡∏ö‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° End
    for i in range(3): 
        await page.keyboard.press("End")
        await page.wait_for_timeout(1000)
        await handle_genius_popup(page)

# --- üå™Ô∏è GENTLE SCROLL (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ) ---
async def gentle_scroll_to_bottom(page):
    print("      üê¢ Scrolling gently to load items...")
    
    # 1. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    previous_height = await page.evaluate("document.body.scrollHeight")
    current_scroll = 0
    
    while True:
        # 2. ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏•‡∏á‡∏ó‡∏µ‡∏•‡∏∞‡∏ô‡∏¥‡∏î (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠)
        # 600px ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏µ ‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        current_scroll += 600 
        await page.evaluate(f"window.scrollTo(0, {current_scroll})")
        
        # 3. ‚è≥ ‡∏´‡∏¢‡∏∏‡∏î‡∏£‡∏≠ 0.5 - 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÉ‡∏´‡πâ‡πÄ‡∏ß‡πá‡∏ö‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å!)
        await asyncio.sleep(random.uniform(0.5, 0.8))
        
        # 4. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ñ‡∏∂‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
        # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡∏á‡∏≠‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°)
        new_height = await page.evaluate("document.body.scrollHeight")
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏•‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏à‡∏ö
        if current_scroll >= new_height:
            # ‡∏¢‡πâ‡∏≥‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏•‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏î‡∏à‡∏£‡∏¥‡∏á‡πÜ
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await asyncio.sleep(1)
            
            # ‡πÄ‡∏ä‡πá‡∏Ñ Double Check ‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏£‡∏¥‡∏á‡πÜ
            final_height = await page.evaluate("document.body.scrollHeight")
            if final_height == new_height:
                break # ‡∏à‡∏ö‡∏Å‡∏≤‡∏£ Scroll
            else:
                previous_height = final_height # ‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡∏°‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏° ‡πÑ‡∏õ‡∏ï‡πà‡∏≠!

# --- üöú CORE LOGIC ---
async def process_location(page, location):
    city = location["name"]
    print(f"\nüåç Traveling to: {city} ({location['province']})...")
    
    # 1. ‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
    future_date = datetime.now() + timedelta(days=120)
    
    # üß† Logic ‡πÄ‡∏™‡∏£‡∏¥‡∏°: ‡∏ñ‡πâ‡∏≤‡∏ß‡∏±‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏î‡∏±‡∏ô‡πÑ‡∏õ‡∏ï‡∏Å "‡∏®‡∏∏‡∏Å‡∏£‡πå(4) ‡∏´‡∏£‡∏∑‡∏≠ ‡πÄ‡∏™‡∏≤‡∏£‡πå(5)" ‡πÉ‡∏´‡πâ‡∏Ç‡∏¢‡∏±‡∏ö‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô "‡∏ß‡∏±‡∏ô‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå"
    # (weekday: 0=Mon, 1=Tue, ..., 6=Sun)
    if future_date.weekday() >= 4: 
        # ‡∏ö‡∏ß‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏õ‡∏≠‡∏µ‡∏Å‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á Weekend ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏ï‡πá‡∏°)
        future_date += timedelta(days=(7 - future_date.weekday()))

    checkin_date = future_date.strftime('%Y-%m-%d')
    checkout_date = (future_date + timedelta(days=1)).strftime('%Y-%m-%d')

    print(f"   üìÖ Targeting Date: {checkin_date} (Aiming for maximum vacancy)")
    
    # URL ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
    params = {
        "ss": city,
        "nflt": "ht_id=213", # Pool Villa
        "group_adults": "2",
        "no_rooms": "1",
        "checkin": checkin_date,
        "checkout": checkout_date
    }
    url = f"{BASE_URL}?{urllib.parse.urlencode(params)}"
    
    try:
        await page.goto(url, timeout=60000)
        await handle_genius_popup(page)
    except Exception as e:
        print(f"‚ùå Connection Failed: {e}")
        return

    # Loop ‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°
    total_rounds = 0
    max_rounds = 50 # ‡∏Å‡∏±‡∏ô‡∏ö‡∏≠‡∏ó‡∏Ñ‡πâ‡∏≤‡∏á
    
    while total_rounds < max_rounds:
        print(f"   üîÑ Round {total_rounds + 1}: Scanning...")

        await gentle_scroll_to_bottom(page)
        
        # 1. ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô
        await scan_current_page_html(page, location)
        
        # 2. ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πå‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Å‡∏î‡∏ï‡∏¥‡∏î‡πÑ‡∏´‡∏°)
        current_card_count = await page.locator('[data-testid="property-card"]').count()
        print(f"      üìç Current Cards: {current_card_count}")

        # 3. Force Scroll ‡πÅ‡∏ö‡∏ö‡πÇ‡∏´‡∏î‡πÜ (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏õ‡∏∏‡πà‡∏°‡πÇ‡∏ú‡∏•‡πà)
        await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        await asyncio.sleep(1)
        await page.keyboard.press("End") # ‡∏¢‡πâ‡∏≥‡∏î‡πâ‡∏ß‡∏¢‡∏õ‡∏∏‡πà‡∏° End
        await asyncio.sleep(2) # ‡∏£‡∏≠ Animation ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏î‡πâ‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤

        # 4. ‡∏´‡∏≤‡∏õ‡∏∏‡πà‡∏° Load More (‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å Selector ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ)
        # Booking ‡∏ä‡∏≠‡∏ö‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ID ‡∏õ‡∏∏‡πà‡∏° ‡πÅ‡∏ï‡πà text ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°
        load_more_btn = page.locator('button:has-text("‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"), button:has-text("Load more results"), [data-testid="show-more-results-button"]')
        
        if await load_more_btn.count() > 0 and await load_more_btn.first.is_visible():
            print("      üñ±Ô∏è Found 'Load More' button. Clicking...")
            
            try:
                # ‡∏Ñ‡∏•‡∏¥‡∏Å‡πÅ‡∏ö‡∏ö Force (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡∏±‡∏á)
                await load_more_btn.first.click(force=True)
                
                # üî• KEY FIX: ‡∏£‡∏≠‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πå‡∏î‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô (Timeout 15‡∏ß‡∏¥)
                # ‡∏ñ‡πâ‡∏≤‡∏Å‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏≤‡∏£‡πå‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô 15 ‡∏ß‡∏¥ ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏ô‡πá‡∏ï‡∏ä‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏∏‡∏î‡∏ó‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß
                try:
                    await page.wait_for_function(
                        f"document.querySelectorAll('[data-testid=\"property-card\"]').length > {current_card_count}",
                        timeout=15000
                    )
                    print("      ‚úÖ New items loaded!")
                except:
                    print("      ‚ö†Ô∏è Clicked but no new items appeared (Might be end of list).")
                    break # ‡∏ñ‡πâ‡∏≤‡∏Å‡∏î‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏°‡∏≤ ‡∏Å‡πá‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏™‡∏∏‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏£‡∏¥‡∏á‡πÜ
                    
            except Exception as e:
                print(f"      ‚ö†Ô∏è Click Error: {e}")
                break
        else:
            print("   üèÅ No 'Load More' button found. Finished.")
            break
            
        total_rounds += 1
        await asyncio.sleep(random.uniform(2, 4)) # ‡∏û‡∏±‡∏Å‡∏´‡∏≤‡∏¢‡πÉ‡∏à

# --- üöÄ MAIN ENTRY POINT ---
async def run_harvester():
    print(f"üî• Hydra Harvester V2.4 (The Zombie) Started...")
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context(
            viewport={'width': 1366, 'height': 768},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
        )
        
        page = await context.new_page()
        current_location_ctx = {"name": "", "province": ""}

        async def handle_response(response):
            if "graphql" in response.url or "searchresults" in response.url:
                try:
                    ctype = response.headers.get("content-type", "")
                    if "application/json" in ctype:
                        json_body = await response.json()
                        await process_json_data(json_body, current_location_ctx)
                except: pass

        page.on("response", handle_response)

        for location in TARGET_LOCATIONS:
            current_location_ctx["name"] = location["name"]
            current_location_ctx["province"] = location["province"]
            
            await process_location(page, location)
            print("   üí§ Cooling down 5s...")
            await asyncio.sleep(5)

        await browser.close()
        print("\nüéâ Mission Complete! All locations scanned.")

if __name__ == "__main__":
    asyncio.run(run_harvester())